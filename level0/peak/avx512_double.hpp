/******************************************************************************
** Copyright (c) 2013-2018, Alexander Heinecke                               **
** All rights reserved.                                                      **
**                                                                           **
** Redistribution and use in source and binary forms, with or without        **
** modification, are permitted provided that the following conditions        **
** are met:                                                                  **
** 1. Redistributions of source code must retain the above copyright         **
**    notice, this list of conditions and the following disclaimer.          **
** 2. Redistributions in binary form must reproduce the above copyright      **
**    notice, this list of conditions and the following disclaimer in the    **
**    documentation and/or other materials provided with the distribution.   **
** 3. Neither the name of the copyright holder nor the names of its          **
**    contributors may be used to endorse or promote products derived        **
**    from this software without specific prior written permission.          **
**                                                                           **
** THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS       **
** "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT         **
** LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR     **
** A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT      **
** HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,    **
** SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED  **
** TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR    **
** PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF    **
** LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING      **
** NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS        **
** SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.              **
******************************************************************************/

void gflops_double_fma(double* data) {
    __asm__ __volatile__("movq %0, %%r8\n\t"
                         "vmovupd (%%r8),  %%zmm0\n\t"
                         "vmovupd (%%r8),  %%zmm1\n\t"
                         "vmovupd (%%r8),  %%zmm2\n\t"
                         "vmovupd (%%r8),  %%zmm3\n\t"
                         "vmovupd (%%r8),  %%zmm4\n\t"
                         "vmovupd (%%r8),  %%zmm5\n\t"
                         "vmovupd (%%r8),  %%zmm6\n\t"
                         "vmovupd (%%r8),  %%zmm7\n\t"
                         "vmovupd (%%r8),  %%zmm8\n\t"
                         "vmovupd (%%r8),  %%zmm9\n\t"
                         "vmovupd (%%r8), %%zmm10\n\t"
                         "vmovupd (%%r8), %%zmm11\n\t"
                         "vmovupd (%%r8), %%zmm12\n\t"
                         "vmovupd (%%r8), %%zmm13\n\t"
                         "vmovupd (%%r8), %%zmm14\n\t"
                         "vmovupd (%%r8), %%zmm15\n\t"
                         "vmovupd (%%r8), %%zmm16\n\t"
                         "vmovupd (%%r8), %%zmm17\n\t"
                         "vmovupd (%%r8), %%zmm18\n\t"
                         "vmovupd (%%r8), %%zmm19\n\t"
                         "vmovupd (%%r8), %%zmm20\n\t"
                         "vmovupd (%%r8), %%zmm21\n\t"
                         "vmovupd (%%r8), %%zmm22\n\t"
                         "vmovupd (%%r8), %%zmm23\n\t"
                         "vmovupd (%%r8), %%zmm24\n\t"
                         "vmovupd (%%r8), %%zmm25\n\t"
                         "vmovupd (%%r8), %%zmm26\n\t"
                         "vmovupd (%%r8), %%zmm27\n\t"
                         "vmovupd (%%r8), %%zmm28\n\t"
                         "vmovupd (%%r8), %%zmm29\n\t"
                         "vmovupd (%%r8), %%zmm30\n\t"
                         "vmovupd (%%r8), %%zmm31\n\t"
                         "movq $100000000, %%r9\n\t" 
                         "1:\n\t"
                         "subq $1, %%r9\n\t"
                         "vfmadd231pd  %%zmm0,  %%zmm0,  %%zmm0\n\t"
                         "vfmadd231pd  %%zmm1,  %%zmm1,  %%zmm1\n\t"
                         "vfmadd231pd  %%zmm2,  %%zmm2,  %%zmm2\n\t"
                         "vfmadd231pd  %%zmm3,  %%zmm3,  %%zmm3\n\t"
                         "vfmadd231pd  %%zmm4,  %%zmm4,  %%zmm4\n\t"
                         "vfmadd231pd  %%zmm5,  %%zmm5,  %%zmm5\n\t"
                         "vfmadd231pd  %%zmm6,  %%zmm6,  %%zmm6\n\t"
                         "vfmadd231pd  %%zmm7,  %%zmm7,  %%zmm7\n\t"
                         "vfmadd231pd  %%zmm8,  %%zmm8,  %%zmm8\n\t"
                         "vfmadd231pd  %%zmm9,  %%zmm9,  %%zmm9\n\t"
                         "vfmadd231pd %%zmm10, %%zmm10, %%zmm10\n\t"
                         "vfmadd231pd %%zmm11, %%zmm11, %%zmm11\n\t"
                         "vfmadd231pd %%zmm12, %%zmm12, %%zmm12\n\t"
                         "vfmadd231pd %%zmm13, %%zmm13, %%zmm13\n\t"
                         "vfmadd231pd %%zmm14, %%zmm14, %%zmm14\n\t"
                         "vfmadd231pd %%zmm15, %%zmm15, %%zmm15\n\t"
                         "vfmadd231pd %%zmm16, %%zmm16, %%zmm16\n\t"
                         "vfmadd231pd %%zmm17, %%zmm17, %%zmm17\n\t"
                         "vfmadd231pd %%zmm18, %%zmm18, %%zmm18\n\t"
                         "vfmadd231pd %%zmm19, %%zmm19, %%zmm19\n\t"
                         "vfmadd231pd %%zmm20, %%zmm20, %%zmm20\n\t"
                         "vfmadd231pd %%zmm21, %%zmm21, %%zmm21\n\t"
                         "vfmadd231pd %%zmm22, %%zmm22, %%zmm22\n\t"
                         "vfmadd231pd %%zmm23, %%zmm23, %%zmm23\n\t"
                         "vfmadd231pd %%zmm24, %%zmm24, %%zmm24\n\t"
                         "vfmadd231pd %%zmm25, %%zmm25, %%zmm25\n\t"
                         "vfmadd231pd %%zmm26, %%zmm26, %%zmm26\n\t"
                         "vfmadd231pd %%zmm27, %%zmm27, %%zmm27\n\t"
                         "vfmadd231pd %%zmm28, %%zmm28, %%zmm28\n\t"
                         "vfmadd231pd %%zmm29, %%zmm29, %%zmm29\n\t"
                         "vfmadd231pd %%zmm30, %%zmm30, %%zmm30\n\t"
                         "vfmadd231pd %%zmm31, %%zmm31, %%zmm31\n\t"
                         "cmpq $0, %%r9\n\t"
                         "jg 1b\n\t"
                        : : "m"(data) : "r8","r9","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15","xmm16","xmm17","xmm18","xmm19","xmm20","xmm21","xmm22","xmm23","xmm24","xmm25","xmm26","xmm27","xmm28","xmm29","xmm30","xmm31");
}

void gflops_double_mul(double* data) {
    __asm__ __volatile__("movq %0, %%r8\n\t"
                         "vmovupd (%%r8),  %%zmm0\n\t"
                         "vmovupd (%%r8),  %%zmm1\n\t"
                         "vmovupd (%%r8),  %%zmm2\n\t"
                         "vmovupd (%%r8),  %%zmm3\n\t"
                         "vmovupd (%%r8),  %%zmm4\n\t"
                         "vmovupd (%%r8),  %%zmm5\n\t"
                         "vmovupd (%%r8),  %%zmm6\n\t"
                         "vmovupd (%%r8),  %%zmm7\n\t"
                         "vmovupd (%%r8),  %%zmm8\n\t"
                         "vmovupd (%%r8),  %%zmm9\n\t"
                         "vmovupd (%%r8), %%zmm10\n\t"
                         "vmovupd (%%r8), %%zmm11\n\t"
                         "vmovupd (%%r8), %%zmm12\n\t"
                         "vmovupd (%%r8), %%zmm13\n\t"
                         "vmovupd (%%r8), %%zmm14\n\t"
                         "vmovupd (%%r8), %%zmm15\n\t"
                         "vmovupd (%%r8), %%zmm16\n\t"
                         "vmovupd (%%r8), %%zmm17\n\t"
                         "vmovupd (%%r8), %%zmm18\n\t"
                         "vmovupd (%%r8), %%zmm19\n\t"
                         "vmovupd (%%r8), %%zmm20\n\t"
                         "vmovupd (%%r8), %%zmm21\n\t"
                         "vmovupd (%%r8), %%zmm22\n\t"
                         "vmovupd (%%r8), %%zmm23\n\t"
                         "vmovupd (%%r8), %%zmm24\n\t"
                         "vmovupd (%%r8), %%zmm25\n\t"
                         "vmovupd (%%r8), %%zmm26\n\t"
                         "vmovupd (%%r8), %%zmm27\n\t"
                         "vmovupd (%%r8), %%zmm28\n\t"
                         "vmovupd (%%r8), %%zmm29\n\t"
                         "vmovupd (%%r8), %%zmm30\n\t"
                         "vmovupd (%%r8), %%zmm31\n\t"
                         "movq $100000000, %%r9\n\t" 
                         "1:\n\t"
                         "subq $1, %%r9\n\t"
                         "vmulpd  %%zmm0,  %%zmm0,  %%zmm0\n\t"
                         "vmulpd  %%zmm1,  %%zmm1,  %%zmm1\n\t"
                         "vmulpd  %%zmm2,  %%zmm2,  %%zmm2\n\t"
                         "vmulpd  %%zmm3,  %%zmm3,  %%zmm3\n\t"
                         "vmulpd  %%zmm4,  %%zmm4,  %%zmm4\n\t"
                         "vmulpd  %%zmm5,  %%zmm5,  %%zmm5\n\t"
                         "vmulpd  %%zmm6,  %%zmm6,  %%zmm6\n\t"
                         "vmulpd  %%zmm7,  %%zmm7,  %%zmm7\n\t"
                         "vmulpd  %%zmm8,  %%zmm8,  %%zmm8\n\t"
                         "vmulpd  %%zmm9,  %%zmm9,  %%zmm9\n\t"
                         "vmulpd %%zmm10, %%zmm10, %%zmm10\n\t"
                         "vmulpd %%zmm11, %%zmm11, %%zmm11\n\t"
                         "vmulpd %%zmm12, %%zmm12, %%zmm12\n\t"
                         "vmulpd %%zmm13, %%zmm13, %%zmm13\n\t"
                         "vmulpd %%zmm14, %%zmm14, %%zmm14\n\t"
                         "vmulpd %%zmm15, %%zmm15, %%zmm15\n\t"
                         "vmulpd %%zmm16, %%zmm16, %%zmm16\n\t"
                         "vmulpd %%zmm17, %%zmm17, %%zmm17\n\t"
                         "vmulpd %%zmm18, %%zmm18, %%zmm18\n\t"
                         "vmulpd %%zmm19, %%zmm19, %%zmm19\n\t"
                         "vmulpd %%zmm20, %%zmm20, %%zmm20\n\t"
                         "vmulpd %%zmm21, %%zmm21, %%zmm21\n\t"
                         "vmulpd %%zmm22, %%zmm22, %%zmm22\n\t"
                         "vmulpd %%zmm23, %%zmm23, %%zmm23\n\t"
                         "vmulpd %%zmm24, %%zmm24, %%zmm24\n\t"
                         "vmulpd %%zmm25, %%zmm25, %%zmm25\n\t"
                         "vmulpd %%zmm26, %%zmm26, %%zmm26\n\t"
                         "vmulpd %%zmm27, %%zmm27, %%zmm27\n\t"
                         "vmulpd %%zmm28, %%zmm28, %%zmm28\n\t"
                         "vmulpd %%zmm29, %%zmm29, %%zmm29\n\t"
                         "vmulpd %%zmm30, %%zmm30, %%zmm30\n\t"
                         "vmulpd %%zmm31, %%zmm31, %%zmm31\n\t"
                         "cmpq $0, %%r9\n\t"
                         "jg 1b\n\t"
                         : : "m"(data) : "r8","r9","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15","xmm16","xmm17","xmm18","xmm19","xmm20","xmm21","xmm22","xmm23","xmm24","xmm25","xmm26","xmm27","xmm28","xmm29","xmm30","xmm31");
}

void gflops_double_add(double* data) {
    __asm__ __volatile__("movq %0, %%r8\n\t"
                         "vmovupd (%%r8),  %%zmm0\n\t"
                         "vmovupd (%%r8),  %%zmm1\n\t"
                         "vmovupd (%%r8),  %%zmm2\n\t"
                         "vmovupd (%%r8),  %%zmm3\n\t"
                         "vmovupd (%%r8),  %%zmm4\n\t"
                         "vmovupd (%%r8),  %%zmm5\n\t"
                         "vmovupd (%%r8),  %%zmm6\n\t"
                         "vmovupd (%%r8),  %%zmm7\n\t"
                         "vmovupd (%%r8),  %%zmm8\n\t"
                         "vmovupd (%%r8),  %%zmm9\n\t"
                         "vmovupd (%%r8), %%zmm10\n\t"
                         "vmovupd (%%r8), %%zmm11\n\t"
                         "vmovupd (%%r8), %%zmm12\n\t"
                         "vmovupd (%%r8), %%zmm13\n\t"
                         "vmovupd (%%r8), %%zmm14\n\t"
                         "vmovupd (%%r8), %%zmm15\n\t"
                         "vmovupd (%%r8), %%zmm16\n\t"
                         "vmovupd (%%r8), %%zmm17\n\t"
                         "vmovupd (%%r8), %%zmm18\n\t"
                         "vmovupd (%%r8), %%zmm19\n\t"
                         "vmovupd (%%r8), %%zmm20\n\t"
                         "vmovupd (%%r8), %%zmm21\n\t"
                         "vmovupd (%%r8), %%zmm22\n\t"
                         "vmovupd (%%r8), %%zmm23\n\t"
                         "vmovupd (%%r8), %%zmm24\n\t"
                         "vmovupd (%%r8), %%zmm25\n\t"
                         "vmovupd (%%r8), %%zmm26\n\t"
                         "vmovupd (%%r8), %%zmm27\n\t"
                         "vmovupd (%%r8), %%zmm28\n\t"
                         "vmovupd (%%r8), %%zmm29\n\t"
                         "vmovupd (%%r8), %%zmm30\n\t"
                         "vmovupd (%%r8), %%zmm31\n\t"
                         "movq $100000000, %%r9\n\t" 
                         "1:\n\t"
                         "subq $1, %%r9\n\t"
                         "vaddpd  %%zmm0,  %%zmm0,  %%zmm0\n\t"
                         "vaddpd  %%zmm1,  %%zmm1,  %%zmm1\n\t"
                         "vaddpd  %%zmm2,  %%zmm2,  %%zmm2\n\t"
                         "vaddpd  %%zmm3,  %%zmm3,  %%zmm3\n\t"
                         "vaddpd  %%zmm4,  %%zmm4,  %%zmm4\n\t"
                         "vaddpd  %%zmm5,  %%zmm5,  %%zmm5\n\t"
                         "vaddpd  %%zmm6,  %%zmm6,  %%zmm6\n\t"
                         "vaddpd  %%zmm7,  %%zmm7,  %%zmm7\n\t"
                         "vaddpd  %%zmm8,  %%zmm8,  %%zmm8\n\t"
                         "vaddpd  %%zmm9,  %%zmm9,  %%zmm9\n\t"
                         "vaddpd %%zmm10, %%zmm10, %%zmm10\n\t"
                         "vaddpd %%zmm11, %%zmm11, %%zmm11\n\t"
                         "vaddpd %%zmm12, %%zmm12, %%zmm12\n\t"
                         "vaddpd %%zmm13, %%zmm13, %%zmm13\n\t"
                         "vaddpd %%zmm14, %%zmm14, %%zmm14\n\t"
                         "vaddpd %%zmm15, %%zmm15, %%zmm15\n\t"
                         "vaddpd %%zmm16, %%zmm16, %%zmm16\n\t"
                         "vaddpd %%zmm17, %%zmm17, %%zmm17\n\t"
                         "vaddpd %%zmm18, %%zmm18, %%zmm18\n\t"
                         "vaddpd %%zmm19, %%zmm19, %%zmm19\n\t"
                         "vaddpd %%zmm20, %%zmm20, %%zmm20\n\t"
                         "vaddpd %%zmm21, %%zmm21, %%zmm21\n\t"
                         "vaddpd %%zmm22, %%zmm22, %%zmm22\n\t"
                         "vaddpd %%zmm23, %%zmm23, %%zmm23\n\t"
                         "vaddpd %%zmm24, %%zmm24, %%zmm24\n\t"
                         "vaddpd %%zmm25, %%zmm25, %%zmm25\n\t"
                         "vaddpd %%zmm26, %%zmm26, %%zmm26\n\t"
                         "vaddpd %%zmm27, %%zmm27, %%zmm27\n\t"
                         "vaddpd %%zmm28, %%zmm28, %%zmm28\n\t"
                         "vaddpd %%zmm29, %%zmm29, %%zmm29\n\t"
                         "vaddpd %%zmm30, %%zmm30, %%zmm30\n\t"
                         "vaddpd %%zmm31, %%zmm31, %%zmm31\n\t"
                         "cmpq $0, %%r9\n\t"
                         "jg 1b\n\t"
                         : : "m"(data) : "r8","r9","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15","xmm16","xmm17","xmm18","xmm19","xmm20","xmm21","xmm22","xmm23","xmm24","xmm25","xmm26","xmm27","xmm28","xmm29","xmm30","xmm31");
}

void gflops_double_madd(double* data) {
    __asm__ __volatile__("movq %0, %%r8\n\t"
                         "vmovupd (%%r8),  %%zmm0\n\t"
                         "vmovupd (%%r8),  %%zmm1\n\t"
                         "vmovupd (%%r8),  %%zmm2\n\t"
                         "vmovupd (%%r8),  %%zmm3\n\t"
                         "vmovupd (%%r8),  %%zmm4\n\t"
                         "vmovupd (%%r8),  %%zmm5\n\t"
                         "vmovupd (%%r8),  %%zmm6\n\t"
                         "vmovupd (%%r8),  %%zmm7\n\t"
                         "vmovupd (%%r8),  %%zmm8\n\t"
                         "vmovupd (%%r8),  %%zmm9\n\t"
                         "vmovupd (%%r8), %%zmm10\n\t"
                         "vmovupd (%%r8), %%zmm11\n\t"
                         "vmovupd (%%r8), %%zmm12\n\t"
                         "vmovupd (%%r8), %%zmm13\n\t"
                         "vmovupd (%%r8), %%zmm14\n\t"
                         "vmovupd (%%r8), %%zmm15\n\t"
                         "vmovupd (%%r8), %%zmm16\n\t"
                         "vmovupd (%%r8), %%zmm17\n\t"
                         "vmovupd (%%r8), %%zmm18\n\t"
                         "vmovupd (%%r8), %%zmm19\n\t"
                         "vmovupd (%%r8), %%zmm20\n\t"
                         "vmovupd (%%r8), %%zmm21\n\t"
                         "vmovupd (%%r8), %%zmm22\n\t"
                         "vmovupd (%%r8), %%zmm23\n\t"
                         "vmovupd (%%r8), %%zmm24\n\t"
                         "vmovupd (%%r8), %%zmm25\n\t"
                         "vmovupd (%%r8), %%zmm26\n\t"
                         "vmovupd (%%r8), %%zmm27\n\t"
                         "vmovupd (%%r8), %%zmm28\n\t"
                         "vmovupd (%%r8), %%zmm29\n\t"
                         "vmovupd (%%r8), %%zmm30\n\t"
                         "vmovupd (%%r8), %%zmm31\n\t"
                         "movq $100000000, %%r9\n\t" 
                         "1:\n\t"
                         "subq $1, %%r9\n\t"
                         "vmulpd  %%zmm0,  %%zmm0,  %%zmm0\n\t"
                         "vaddpd  %%zmm1,  %%zmm1,  %%zmm1\n\t"
                         "vmulpd  %%zmm2,  %%zmm2,  %%zmm2\n\t"
                         "vaddpd  %%zmm3,  %%zmm3,  %%zmm3\n\t"
                         "vmulpd  %%zmm4,  %%zmm4,  %%zmm4\n\t"
                         "vaddpd  %%zmm5,  %%zmm5,  %%zmm5\n\t"
                         "vmulpd  %%zmm6,  %%zmm6,  %%zmm6\n\t"
                         "vaddpd  %%zmm7,  %%zmm7,  %%zmm7\n\t"
                         "vmulpd  %%zmm8,  %%zmm8,  %%zmm8\n\t"
                         "vaddpd  %%zmm9,  %%zmm9,  %%zmm9\n\t"
                         "vmulpd %%zmm10, %%zmm10, %%zmm10\n\t"
                         "vaddpd %%zmm11, %%zmm11, %%zmm11\n\t"
                         "vmulpd %%zmm12, %%zmm12, %%zmm12\n\t"
                         "vaddpd %%zmm13, %%zmm13, %%zmm13\n\t"
                         "vmulpd %%zmm14, %%zmm14, %%zmm14\n\t"
                         "vaddpd %%zmm15, %%zmm15, %%zmm15\n\t"
                         "vmulpd %%zmm16, %%zmm16, %%zmm16\n\t"
                         "vaddpd %%zmm17, %%zmm17, %%zmm17\n\t"
                         "vmulpd %%zmm18, %%zmm18, %%zmm18\n\t"
                         "vaddpd %%zmm19, %%zmm19, %%zmm19\n\t"
                         "vmulpd %%zmm20, %%zmm20, %%zmm20\n\t"
                         "vaddpd %%zmm21, %%zmm21, %%zmm21\n\t"
                         "vmulpd %%zmm22, %%zmm22, %%zmm22\n\t"
                         "vaddpd %%zmm23, %%zmm23, %%zmm23\n\t"
                         "vmulpd %%zmm24, %%zmm24, %%zmm24\n\t"
                         "vaddpd %%zmm25, %%zmm25, %%zmm25\n\t"
                         "vmulpd %%zmm26, %%zmm26, %%zmm26\n\t"
                         "vaddpd %%zmm27, %%zmm27, %%zmm27\n\t"
                         "vmulpd %%zmm28, %%zmm28, %%zmm28\n\t"
                         "vaddpd %%zmm29, %%zmm29, %%zmm29\n\t"
                         "vmulpd %%zmm30, %%zmm30, %%zmm30\n\t"
                         "vaddpd %%zmm31, %%zmm31, %%zmm31\n\t"
                         "cmpq $0, %%r9\n\t"
                         "jg 1b\n\t"
                         : : "m"(data) : "r8","r9","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15","xmm16","xmm17","xmm18","xmm19","xmm20","xmm21","xmm22","xmm23","xmm24","xmm25","xmm26","xmm27","xmm28","xmm29","xmm30","xmm31");
}

